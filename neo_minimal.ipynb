{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/kandarpa02/neonet.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:19:41.874608Z","iopub.execute_input":"2025-07-18T16:19:41.875282Z","iopub.status.idle":"2025-07-18T16:19:48.393082Z","shell.execute_reply.started":"2025-07-18T16:19:41.875256Z","shell.execute_reply":"2025-07-18T16:19:48.392380Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/kandarpa02/neonet.git\n  Cloning https://github.com/kandarpa02/neonet.git to /tmp/pip-req-build-2ql3ovk1\n  Running command git clone --filter=blob:none --quiet https://github.com/kandarpa02/neonet.git /tmp/pip-req-build-2ql3ovk1\n  Resolved https://github.com/kandarpa02/neonet.git to commit ab86f58baa51cf9175b60bf74be573731f209e10\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: neonet\n  Building wheel for neonet (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for neonet: filename=neonet-0.0.1a1-py3-none-any.whl size=7385 sha256=8e700a56d896e4a9e82aca94585abbc37a69fa33cbf64ada66ae6b5bf8ff1659\n  Stored in directory: /tmp/pip-ephem-wheel-cache-s221lttu/wheels/30/68/a3/1e288d38f0373f2c46d66052dfbc2f2bc5a647564ceaa6b289\nSuccessfully built neonet\nInstalling collected packages: neonet\nSuccessfully installed neonet-0.0.1a1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import neonet as neo\nimport neonet.numpy as nep\nfrom neonet import autograd\nfrom neonet.functions import fn_forward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:19:48.394734Z","iopub.execute_input":"2025-07-18T16:19:48.394967Z","iopub.status.idle":"2025-07-18T16:19:49.794921Z","shell.execute_reply.started":"2025-07-18T16:19:48.394947Z","shell.execute_reply":"2025-07-18T16:19:49.794365Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# You can define any funcion and its backward rule\n# with autograd.Policy module, its inner working a bit\n# verbose, I wil make everythng clear once it is complete\n\nclass IF_IT_WORKS_DONT_TOUCH_IT(autograd.Policy):\n    def forward(self, X, Y, b):\n        self.ctx.save(X, Y, b)\n        return (X @ Y) + b\n    \n    def backward(self, grad):\n        X, Y, b = self.ctx.release\n        x_grad = grad @ Y.T\n        y_grad = X.T @ grad\n        b_grad = grad.sum(axis=0) if b.size > 1 else grad.sum()\n        return x_grad, y_grad, b_grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:25:59.097119Z","iopub.execute_input":"2025-07-18T16:25:59.097626Z","iopub.status.idle":"2025-07-18T16:25:59.102423Z","shell.execute_reply.started":"2025-07-18T16:25:59.097603Z","shell.execute_reply":"2025-07-18T16:25:59.101654Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"X = neo.randn((3,4), device='cuda') # for 'cuda' it uses cupy under the hood (numpy's evil twin)\nY = neo.randn((4,2), device='cuda')\nb = neo.randn((2,), device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:26:00.188579Z","iopub.execute_input":"2025-07-18T16:26:00.189117Z","iopub.status.idle":"2025-07-18T16:26:00.193516Z","shell.execute_reply.started":"2025-07-18T16:26:00.189092Z","shell.execute_reply":"2025-07-18T16:26:00.192905Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(f\"matrix X\\n{X}\")\nprint(f\"matrixY\\n{Y}\")\nprint(f\"vector b\\n{b}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:26:00.434113Z","iopub.execute_input":"2025-07-18T16:26:00.434356Z","iopub.status.idle":"2025-07-18T16:26:00.440058Z","shell.execute_reply.started":"2025-07-18T16:26:00.434338Z","shell.execute_reply":"2025-07-18T16:26:00.439351Z"}},"outputs":[{"name":"stdout","text":"matrix X\n[[ 1.53645926  0.68121459  0.10153642 -0.62356898]\n [ 2.08279636  1.0575698   0.86665142 -0.30455532]\n [ 0.73587747 -1.62454334 -0.89650051 -0.64107397]]\nmatrixY\n[[ 0.78848922 -0.91403799]\n [ 0.8977777   0.00596389]\n [-1.81868782  1.41260409]\n [ 0.88750909 -0.32401679]]\nvector b\n[-0.10963281  1.1082946 ]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"forward = fn_forward(IF_IT_WORKS_DONT_TOUCH_IT)\n\nout, grads = autograd.value_and_grad(forward)(X, Y, b)\nprint(\"Output :\\n\", out, \"\\n\")\n\nmatrices = list(grads.values())\nnames = [\"X_grad\", \"Y_grad\", \"b_grad\"]\n\nfor name, mat in zip(names, matrices):\n    print(f\"Matrix {name}:\\n{mat}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:33:10.072603Z","iopub.execute_input":"2025-07-18T16:33:10.072881Z","iopub.status.idle":"2025-07-18T16:33:10.080214Z","shell.execute_reply.started":"2025-07-18T16:33:10.072860Z","shell.execute_reply":"2025-07-18T16:33:10.079500Z"}},"outputs":[{"name":"stdout","text":"Output :\n [[ 0.97534184  0.05345273]\n [ 0.63562825  0.53376321]\n [ 0.07361545 -0.63269553]] \n\nMatrix X_grad:\n[[-0.12554877  0.90374159 -0.40608373  0.5634923 ]\n [-0.12554877  0.90374159 -0.40608373  0.5634923 ]\n [-0.12554877  0.90374159 -0.40608373  0.5634923 ]]\n\nMatrix Y_grad:\n[[ 4.3551331   4.3551331 ]\n [ 0.11424104  0.11424104]\n [ 0.07168733  0.07168733]\n [-1.56919827 -1.56919827]]\n\nMatrix b_grad:\n[3. 3.]\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import jax.numpy as jnp\nfrom jax import grad as gfn\n\nX_, Y_, b_ = X.to('cpu').numpy(), Y.to('cpu').numpy(), b.to('cpu').numpy()\n\ngrads_jax = gfn(lambda x, y, b: (x@y + b).sum(), argnums=[0,1,2])(X_, Y_, b_)\n\nmatrices = list(grads_jax)\nnames = [\"X_JAX_grad\", \"Y_JAX_grad\", \"b_JAX_grad\"]\n\nfor name, mat in zip(names, matrices):\n    print(f\"Matrix {name}:\\n{mat}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T16:34:19.990888Z","iopub.execute_input":"2025-07-18T16:34:19.991681Z","iopub.status.idle":"2025-07-18T16:34:20.003660Z","shell.execute_reply.started":"2025-07-18T16:34:19.991656Z","shell.execute_reply":"2025-07-18T16:34:20.003145Z"}},"outputs":[{"name":"stdout","text":"Matrix X_JAX_grad:\n[[-0.12554878  0.90374154 -0.4060837   0.5634923 ]\n [-0.12554878  0.90374154 -0.4060837   0.5634923 ]\n [-0.12554878  0.90374154 -0.4060837   0.5634923 ]]\n\nMatrix Y_JAX_grad:\n[[ 4.355133    4.355133  ]\n [ 0.114241    0.114241  ]\n [ 0.07168728  0.07168728]\n [-1.5691983  -1.5691983 ]]\n\nMatrix b_JAX_grad:\n[3. 3.]\n\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}