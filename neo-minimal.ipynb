{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/kandarpa02/neonet.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:12.062370Z","iopub.execute_input":"2025-07-18T19:18:12.062631Z","iopub.status.idle":"2025-07-18T19:18:19.365088Z","shell.execute_reply.started":"2025-07-18T19:18:12.062607Z","shell.execute_reply":"2025-07-18T19:18:19.364383Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/kandarpa02/neonet.git\n  Cloning https://github.com/kandarpa02/neonet.git to /tmp/pip-req-build-br1xvgem\n  Running command git clone --filter=blob:none --quiet https://github.com/kandarpa02/neonet.git /tmp/pip-req-build-br1xvgem\n  Resolved https://github.com/kandarpa02/neonet.git to commit 7a4bc5826f457123a64de4db03cdb87e485a8307\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: neonet\n  Building wheel for neonet (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for neonet: filename=neonet-0.0.1a1-py3-none-any.whl size=9031 sha256=c6cbe0151c80a93c1dade0279dc326c622cde66a8e91a579f3c475760a6d4e1a\n  Stored in directory: /tmp/pip-ephem-wheel-cache-bntaa5_a/wheels/30/68/a3/1e288d38f0373f2c46d66052dfbc2f2bc5a647564ceaa6b289\nSuccessfully built neonet\nInstalling collected packages: neonet\nSuccessfully installed neonet-0.0.1a1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import neo\nimport neo.numpy as nep\nfrom neo import autograd\nfrom neo.functions import fn_forward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:19.366599Z","iopub.execute_input":"2025-07-18T19:18:19.367473Z","iopub.status.idle":"2025-07-18T19:18:20.732961Z","shell.execute_reply.started":"2025-07-18T19:18:19.367439Z","shell.execute_reply":"2025-07-18T19:18:20.732180Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# You can define any funcion and its backward rule\n# with autograd.Policy module, its inner working a bit\n# verbose, I wil make everythng clear once it is complete\n\nclass IF_IT_WORKS_DONT_TOUCH_IT(autograd.Policy):\n    def forward(self, X, Y, b):\n        self.ctx.save(X, Y, b)\n        return (X @ Y) + b\n    \n    def backward(self, grad):\n        X, Y, b = self.ctx.release\n        x_grad = grad @ Y.T\n        y_grad = X.T @ grad\n        b_grad = grad.sum(axis=0) if b.size > 1 else grad.sum()\n        return x_grad, y_grad, b_grad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:35.374376Z","iopub.execute_input":"2025-07-18T19:18:35.374799Z","iopub.status.idle":"2025-07-18T19:18:35.380393Z","shell.execute_reply.started":"2025-07-18T19:18:35.374768Z","shell.execute_reply":"2025-07-18T19:18:35.379709Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"X = neo.randn((3,4), device='cuda') # for 'cuda' it uses cupy under the hood (numpy's evil twin)\nY = neo.randn((4,2), device='cuda')\nb = neo.randn((2,), device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:37.334763Z","iopub.execute_input":"2025-07-18T19:18:37.334996Z","iopub.status.idle":"2025-07-18T19:18:37.561122Z","shell.execute_reply.started":"2025-07-18T19:18:37.334978Z","shell.execute_reply":"2025-07-18T19:18:37.560343Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(f\"matrix X\\n{X}\")\nprint(f\"matrixY\\n{Y}\")\nprint(f\"vector b\\n{b}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:40.561579Z","iopub.execute_input":"2025-07-18T19:18:40.562177Z","iopub.status.idle":"2025-07-18T19:18:40.567790Z","shell.execute_reply.started":"2025-07-18T19:18:40.562152Z","shell.execute_reply":"2025-07-18T19:18:40.567130Z"}},"outputs":[{"name":"stdout","text":"matrix X\n[[ 1.63607024  0.65679874  0.49440371 -1.00391713]\n [-0.14999782  1.11938317 -1.35716351 -0.21304375]\n [-0.03646202  0.55950737 -1.20680271  0.70346151]]\nmatrixY\n[[-0.86843071  1.05386462]\n [-0.9428054   1.17611029]\n [ 1.19467713  0.51843372]\n [ 0.5259126   0.19863528]]\nvector b\n[ 1.32473385 -1.3522553 ]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"forward = fn_forward(IF_IT_WORKS_DONT_TOUCH_IT)\n\nout, grads = autograd.session.value_and_grad(forward)(X, Y, b)\nprint(\"Output :\\n\", out, \"\\n\")\n\nmatrices = list(grads.values())\nnames = [\"X_grad\", \"Y_grad\", \"b_grad\"]\n\nfor name, mat in zip(names, matrices):\n    print(f\"Matrix {name}:\\n{mat}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:18:48.754660Z","iopub.execute_input":"2025-07-18T19:18:48.755211Z","iopub.status.idle":"2025-07-18T19:18:49.879820Z","shell.execute_reply.started":"2025-07-18T19:18:48.755187Z","shell.execute_reply":"2025-07-18T19:18:49.879061Z"}},"outputs":[{"name":"stdout","text":"Output :\n [[-0.65263305  1.20131121]\n [-1.33377853 -0.93973197]\n [-0.24288831 -1.21855391]] \n\nMatrix X_grad:\n[[0.18543391 0.23330489 1.71311085 0.72454788]\n [0.18543391 0.23330489 1.71311085 0.72454788]\n [0.18543391 0.23330489 1.71311085 0.72454788]]\n\nMatrix Y_grad:\n[[ 1.4496104   1.4496104 ]\n [ 2.33568928  2.33568928]\n [-2.0695625  -2.0695625 ]\n [-0.51349937 -0.51349937]]\n\nMatrix b_grad:\n[3. 3.]\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import jax.numpy as jnp\nfrom jax import grad as gfn\n\nX_, Y_, b_ = X.to('cpu').numpy(), Y.to('cpu').numpy(), b.to('cpu').numpy()\n\ngrads_jax = gfn(lambda x, y, b: (x@y + b).sum(), argnums=[0,1,2])(X_, Y_, b_)\n\nmatrices = list(grads_jax)\nnames = [\"X_JAX_grad\", \"Y_JAX_grad\", \"b_JAX_grad\"]\n\nfor name, mat in zip(names, matrices):\n    print(f\"Matrix {name}:\\n{mat}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T19:19:03.088702Z","iopub.execute_input":"2025-07-18T19:19:03.089292Z","iopub.status.idle":"2025-07-18T19:19:06.703130Z","shell.execute_reply.started":"2025-07-18T19:19:03.089251Z","shell.execute_reply":"2025-07-18T19:19:06.702440Z"}},"outputs":[{"name":"stderr","text":"INFO:2025-07-18 19:19:05,301:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nINFO:2025-07-18 19:19:05,314:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n","output_type":"stream"},{"name":"stdout","text":"Matrix X_JAX_grad:\n[[0.18543386 0.23330486 1.7131109  0.72454786]\n [0.18543386 0.23330486 1.7131109  0.72454786]\n [0.18543386 0.23330486 1.7131109  0.72454786]]\n\nMatrix Y_JAX_grad:\n[[ 1.4496104  1.4496104]\n [ 2.3356893  2.3356893]\n [-2.0695624 -2.0695624]\n [-0.5134994 -0.5134994]]\n\nMatrix b_JAX_grad:\n[3. 3.]\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}